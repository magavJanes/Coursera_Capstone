{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTransformator( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        self._binary_mapping = {'bin_3': {'F':0, 'T':1}, 'bin_4': {'N':0, 'Y':1}}\n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        self._bin_columns = [ column for column in X.columns if column.find('bin_') != -1 ]\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        for column in self._bin_columns:\n",
    "            if X[column].dtype == np.object:\n",
    "                X[column] = X[column].replace(self._binary_mapping[column])\n",
    "#            X[column] = X[column].fillna(-1)\n",
    "            self._df[column+'_0'] = (X[column] == 0).astype(np.int)\n",
    "            self._df[column+'_1'] = (X[column] == 1).astype(np.int)\n",
    "#            self._df[column+'_0'] = X[column].apply(lambda x: -1 if x == -1 else int(x==0))\n",
    "#            self._df[column+'_1'] = X[column].apply(lambda x: -1 if x == -1 else int(x==1))\n",
    "\n",
    "        #self._df = self._df.reset_index(drop=True)\n",
    "        print('Binary transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class NominalTransformator( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        #self._le = LabelEncoder()\n",
    "        return\n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        #self._nom_columns = [ column for column in X.columns if column.find('nom_') != -1 ]\n",
    "        self._n_features = np.ceil(np.log(len(X['nom_9'].value_counts().index))).astype(np.int)\n",
    "        #self._n_features = 15\n",
    "        #self._le.fit(X[self._nom_columns])\n",
    "        #for i in range(5,10):\n",
    "        #    self._nom_hash_features['nom_{}'.format(i)] = np.log(len(X['nom_{}'.format(i)].value_counts().index))\n",
    "        #    print('nom_{} - {}'.format(i, self._nom_hash_features['nom_{}'.format(i)]))\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        hex_symbols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f']\n",
    "\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        # from nom_0 to nom_4\n",
    "        for i in range(5):\n",
    "            categories = X['nom_{}'.format(i)].value_counts().index\n",
    "            for category in categories:\n",
    "                self._df['nom_{}_{}'.format(i, category)] = (X['nom_{}'.format(i)] == category).astype(np.int)\n",
    "        \n",
    "# spresd characters\n",
    "#        X['noms59'] = X[['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']].fillna('').agg(''.join, axis=1)\n",
    "#        for s in hex_symbols:\n",
    "#            self._df['nom_hex_'+s] = X['noms59'].apply(lambda x : x.count(s))\n",
    "        result = self._df.values\n",
    "        # feature hash\n",
    "        fh = FeatureHasher(n_features=self._n_features, input_type='string')\n",
    "        for i in range(5,10):\n",
    "            hashed_features = fh.fit_transform(X['nom_{}'.format(i)].fillna('0000000'))\n",
    "            result = np.hstack((result,hashed_features.toarray()))\n",
    "            #self._df['nom_{}'.format(i)] = X['nom_{}'.format(i)].fillna('0').apply(lambda x : int(x,16))\n",
    "        \n",
    "        #self._df = self._df.reset_index(drop=True)\n",
    "        print('Nominal transform shape is {}'.format(result.shape))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OrdinaryTransformator( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        self._ordinary_mapping = {\n",
    "                                      'ord_1': {'Novice':1, 'Expert':2, 'Contributor':3, 'Master':4, 'Grandmaster':5}, \n",
    "                                      'ord_2': {'Freezing':1, 'Cold':2, 'Warm':3, 'Hot':4, 'Boiling Hot':5, 'Lava Hot':6}\n",
    "                                 }\n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        self._df['missing_data'] = X.isna().sum(axis=1)\n",
    "        self._df['ord_0'] = X['ord_0'].fillna(0)\n",
    "        self._df['ord_1'] = X['ord_1'].replace({'Novice':1, 'Expert':2, 'Contributor':3, 'Master':4, 'Grandmaster':5}).fillna(0)\n",
    "        self._df['ord_2'] = X['ord_2'].replace({'Freezing':1, 'Cold':2, 'Warm':3, 'Hot':4, 'Boiling Hot':5, 'Lava Hot':6}).fillna(0)\n",
    "\n",
    "        self._df['ord_3'] = X['ord_3'].fillna('0').apply(lambda x: ord(x))\n",
    "        self._df['ord_4'] = X['ord_4'].fillna('0').apply(lambda x: ord(x))\n",
    "        self._df['ord_5'] = X['ord_5'].fillna('0').apply(lambda x: 0 if x=='0' else ord(x[0])*10+ord(x[1]))\n",
    "#        self._df['ord_5_1'] = X['ord_5'].fillna('00').apply(lambda x: 0 if x=='00' else ord(x[0]))\n",
    "#        self._df['ord_5_2'] = X['ord_5'].fillna('00').apply(lambda x: 0 if x=='00' else ord(x[1]))\n",
    "\n",
    "        '''\n",
    "        side coding\n",
    "        self._df['ord_3'] = X['ord_3'].fillna('0').apply(lambda x: -1 if x=='0' else ord(x))\n",
    "        self._df['ord_3'] = self._df['ord_3'].apply(lambda x: -1 if x == 0 else x )\n",
    "        self._df['ord_4'] = X['ord_4'].fillna('0').apply(lambda x:  -1 if x=='0' else ord(x))\n",
    "        self._df['ord_4'] = self._df['ord_4'].apply(lambda x: -1 if x == 0 else x )\n",
    "        self._df['ord_5_1'] = X['ord_5'].fillna('00').apply(lambda x: -1 if x=='00' else ord(x[0]))\n",
    "        self._df['ord_5_2'] = X['ord_5'].fillna('00').apply(lambda x: -1 if x=='00' else ord(x[1]))\n",
    "        '''\n",
    "\n",
    "        #self._df = self._df.reset_index(drop=True)\n",
    "        print('Ordinary transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CycleTransformator( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        self._cycle_columns = ['day', 'month']\n",
    "        self._cycle_stats = {}\n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        \n",
    "        for column in self._cycle_columns:\n",
    "            self._cycle_stats[column] = {'max': X[column].max(), 'min': X[column].min()}\n",
    "        return self\n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        self._df = pd.DataFrame(index=X.index)\n",
    "        for column in self._cycle_columns:\n",
    "            self._df[column+'_sin'] = np.sin(2*np.pi/(self._cycle_stats[column]['max']+1)*X[column].fillna(self._cycle_stats[column]['min']-1))\n",
    "            self._df[column+'_cos'] = np.cos(2*np.pi/(self._cycle_stats[column]['max']+1)*X[column].fillna(self._cycle_stats[column]['min']-1))\n",
    "\n",
    "        #self._df = self._df.reset_index(drop=True)\n",
    "        print('Cycle transform shape is {}'.format(self._df.values.shape))\n",
    "        return self._df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600000, 23)\n",
      "(600000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary transform shape is (480000, 10)\n",
      "Ordinary transform shape is (480000, 7)\n",
      "Nominal transform shape is (480000, 65)\n",
      "Cycle transform shape is (480000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Std Deviation:\", scores.std())\n",
    "\n",
    "pd_train = pd.read_csv('train.csv', index_col='id')\n",
    "pd_test = pd.read_csv('test.csv', index_col='id')\n",
    "X_train = pd_train.drop('target', axis=1)\n",
    "X_test = pd_test\n",
    "y_train = pd_train['target'].values\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "data_pipeline = FeatureUnion( transformer_list = [ \n",
    "                                                   ( 'binary', BinaryTransformator() ), \n",
    "                                                   ( 'ordinary', OrdinaryTransformator() ), \n",
    "                                                   ( 'nominal', NominalTransformator() ), \n",
    "                                                   ( 'cycle', CycleTransformator() ), \n",
    "                                                 ]\n",
    "                            )\n",
    "\n",
    "#model_pipeline = FeatureUnion( steps\n",
    "#                         )\n",
    "cat2_pipeline = Pipeline( \n",
    "                          steps = [ ( 'data', data_pipeline ),                          \n",
    "                                    ( 'std_scaler', StandardScaler() ), \n",
    "                                    ( 'bagging', BaggingClassifier(LinearSVC(), n_estimators=200, max_samples=0.3, max_features=0.3, n_jobs=2,random_state=579, verbose=2)  )\n",
    "#                                    ( 'forest', RandomForestClassifier(n_estimators=500, max_samples=0.2 ,max_features=0.5, n_jobs=2,random_state=579, verbose=1)  )\n",
    "                                  ] \n",
    "                        )\n",
    "#cat2_pipeline.fit( X_train, y_train )\n",
    "scores = cross_val_score(cat2_pipeline, X_train, y_train, scoring=\"roc_auc\", cv=5, verbose=1)\n",
    "\n",
    "#X_test.to_csv('prediction_rf03.csv', columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2_pipeline.fit( X_train, y_train )\n",
    "X_test['target'] = cat2_pipeline.predict_proba( X_test )[:,1]\n",
    "X_test.to_csv('prediction_bag03.csv', columns=['target'])#, float_format='%.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
